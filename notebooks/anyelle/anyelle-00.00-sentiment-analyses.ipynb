{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHgXYGaqR3FA"
   },
   "source": [
    "# Sentiment Analyses with imdb data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO92oVb7Ai1c"
   },
   "source": [
    "## Connecting notebook with drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BK7SIVi_R7vn"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEL3Pp3OSBQI",
    "outputId": "304edac3-e308-45a3-9a0c-8f411b1735a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KzrHc4LTSCFb"
   },
   "outputs": [],
   "source": [
    "os.chdir('drive/MyDrive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgeM_MydAqJX"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBqFFbbcSMLT",
    "outputId": "bc8361d2-9015-4770-88d7-5995a8623f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# libraries to clean text\n",
    "import re\n",
    "from   nltk                                   import download\n",
    "from   nltk.tokenize                          import word_tokenize\n",
    "from   nltk.corpus                            import stopwords\n",
    "from   nltk.tokenize                          import word_tokenize\n",
    "from   nltk.stem                              import WordNetLemmatizer\n",
    "from   nltk                                   import pos_tag\n",
    "\n",
    "# required resources for NLTK\n",
    "download(\"stopwords\")\n",
    "download(\"punkt\")\n",
    "download(\"wordnet\")\n",
    "download(\"omw-1.4\")\n",
    "download('averaged_perceptron_tagger') \n",
    "\n",
    "# libraries to minupulate data\n",
    "import numpy                                  as     np\n",
    "import pandas                                 as     pd\n",
    "from   sklearn.feature_extraction.text        import TfidfVectorizer\n",
    "\n",
    "# libraries to plot\n",
    "import wordcloud\n",
    "import matplotlib.pyplot                      as     plt\n",
    "\n",
    "# libraries for sentiment analysis baseline\n",
    "import pickle\n",
    "import tensorflow_datasets                    as     tfds\n",
    "from   sklearn.model_selection                import cross_validate\n",
    "from   sklearn.naive_bayes                    import MultinomialNB\n",
    "from   tensorflow.keras.preprocessing.text    import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtkxdmQMAzjA"
   },
   "source": [
    "## Retriving and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "MBBwC_FsSMVK",
    "outputId": "86e16c37-3df4-4d2d-f3e4-a8f5b2930983"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7125c1fd-aa91-45d1-a7bb-3c881aab9222\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7125c1fd-aa91-45d1-a7bb-3c881aab9222')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7125c1fd-aa91-45d1-a7bb-3c881aab9222 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7125c1fd-aa91-45d1-a7bb-3c881aab9222');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb = pd.read_csv(\"imdb_data.csv\")\n",
    "data_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "pGB7og3oSMc9",
    "outputId": "7c60bbf4-277f-4a3f-dc8c-bab977bd6133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f32b8f56-326b-442f-9664-d7b77c620622\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f32b8f56-326b-442f-9664-d7b77c620622')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f32b8f56-326b-442f-9664-d7b77c620622 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f32b8f56-326b-442f-9664-d7b77c620622');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb['sentiment'] = data_imdb['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "data_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F6TCZM2wSahP"
   },
   "outputs": [],
   "source": [
    "def split_into_sentences( text, split_pattern = [\".\", \"!\", \"?\"] ):\n",
    "    \"\"\"Split a text on . or ? or ! symbol.\n",
    "    Note: the text is not cleaned, only split.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        split_pattern: a list with characters to split the sentence.\n",
    "            These characters must be . or ? or !\n",
    "    Return\n",
    "        sentences: list with split text.\"\"\"\n",
    "\n",
    "    # check if split_pattern is a list object\n",
    "    if not isinstance(split_pattern, list):\n",
    "        # invalid split_patter format\n",
    "        raise Exception(\"Invalid param: split_pattern format! It must be a list.\")\n",
    "\n",
    "    # check if split pattern contains only . or ! or ?\n",
    "    if len(set(split_pattern) - {\".\", \"!\", \"?\"}) > 0:\n",
    "        # invalid split patter\n",
    "        raise Exception(\"Invalid param: split_pattern! It must be . or ! or ?\")\n",
    "\n",
    "    # import required libraries\n",
    "    import re\n",
    "\n",
    "    # define split\n",
    "    regex_split = \"\".join(split_pattern)\n",
    "\n",
    "    # split when . or ? or ! is found\n",
    "    sentences = re.split(f\"[{regex_split}]+\", text)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def remove_emails( text, replacer = \" \" ):\n",
    "    \"\"\"Remove email addresses from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the emails.\n",
    "    Return\n",
    "        text: string with processed text.\n",
    "    NOTE: to avoid errors on email removing, remove_email function\n",
    "        must be used before removing_mentions fucntion (@)\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # remove emails with regex\n",
    "    text = re.sub(\"[a-zA-Z0-9_.+-]+@([a-zA-Z0-9-]+\\.)+[a-zA-Z0-9-]+\", replacer, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_mentions( text, replacer = \" \"):\n",
    "    \"\"\"Remove mentions of the @some_word format from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the mentions.\n",
    "    Return\n",
    "        text: string with processed text.\n",
    "    NOTE: to avoid errors on mentions removing, remove_email function\n",
    "        must be used before removing_mentions fucntion (@)\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # remove mention with regex\n",
    "    text = re.sub(\"@\\w+\", replacer, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_hashtags( text, replacer = \" \" ):\n",
    "    \"\"\"Remove hashtag of the #some_word format from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the hashtags.\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # remove hashtag with regex\n",
    "    text = re.sub(\"#\\w+\", replacer, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_urls( text, replacer = \" \" ):\n",
    "    \"\"\"Remove any url from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the urls.\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # remove any url with regex\n",
    "    text = re.sub(\"(https://|http://|www.)\\S+\",\n",
    "                  replacer,\n",
    "                  text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_html_tags( text, replacer = \" \" ):\n",
    "    \"\"\"Remove any html tags from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the html tags.\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # remove any url with regex\n",
    "    text = re.sub(\"<.*?>\", replacer, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_spaces( text, replacer = \" \" ):\n",
    "    \"\"\"Remove any spaces from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the spaces\n",
    "    Return\n",
    "        text: string with processed text.\n",
    "    NOTE: When removing word with regex, the best prectice seems to be\n",
    "        removing the substituted word with \" \" (space) and not \"\" (empty).\n",
    "        Then, after all replacings, use the remove_space the deal with all spaces\n",
    "        that were created. In other words, use the remove_spaces function\n",
    "        as the last step of data cleaning\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # remove any spaces with regex\n",
    "    text = re.sub(\"\\s+\", replacer, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lower_caser( text ):\n",
    "    \"\"\"Lower the case of the words in a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "    Return\n",
    "        text: string with lower cased text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    return text.lower() # lower case\n",
    "\n",
    "\n",
    "def remove_punctuation( text, replacer = \" \" ):\n",
    "    \"\"\"Remove the punctuation of a text.\n",
    "    Args:\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the punctuations\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # import required libraries\n",
    "    import string\n",
    "\n",
    "    # iterate over punctuation symbols\n",
    "    for punctuation in string.punctuation:\n",
    "\n",
    "        # remove punctuation from string\n",
    "        text = text.replace(punctuation, replacer)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize( text ):\n",
    "    \"\"\"Lemmatize the words in a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # import required libraries\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    # instanciate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # iterate over words in text and lemmatize\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "\n",
    "    # join lemmatized items\n",
    "    lemmatized_text = \" \".join(lemmatized_text)\n",
    "\n",
    "    return lemmatized_text\n",
    "\n",
    "\n",
    "def remove_stopwords( text ):\n",
    "    \"\"\"First it gets the negative stop words and convert it into \"not\" word.\n",
    "    Then, it removes all other stop words (but not the \"not\" word previously created.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # define the english negative stop words\n",
    "    negative_stop_words = [\"no\", \"nor\", \"not\", \"don\", \"don't\", \"ain\", \"ain't\", \"aren\", \"aren't\",\n",
    "                           \"couldn\", \"couldn't\", \"didn\", \"didn't\", \"doesn\", \"doesn't\", \"hadn\", \"hadn't\",\n",
    "                           \"hasn\", \"hasn't\", \"haven\",  \"haven't\", \"isn\", \"isn't\", \"mightn\", \"mightn't\",\n",
    "                           \"mustn\", \"mustn't\", \"needn\", \"needn't\", \"shan\", \"shan't\", \"shouldn\", \"shouldn't\",\n",
    "                           \"wasn\", \"wasn't\", \"weren\", \"weren't\", \"won\", \"won't\", \"wouldn\", \"wouldn't\"]\n",
    "\n",
    "    # iterate over words in text\n",
    "    # if word is one of the negative stop words, replace with \"not\"\n",
    "    # else keep the word as it is\n",
    "    # result will be a tokenized text\n",
    "    tokens_with_neg = [\"not\" if word in negative_stop_words else word\n",
    "                       for word in text.split()]\n",
    "\n",
    "    # get the standard unique stopwords in English\n",
    "    # according to NLTK\n",
    "    std_stop_words = stopwords.words('english')\n",
    "\n",
    "    # remove negative stop words from standard stop words\n",
    "    final_stop_words = set(std_stop_words) - set(negative_stop_words)\n",
    "\n",
    "    # remove stop words\n",
    "    text = \" \".join( [word for word in tokens_with_neg if not word in final_stop_words] )\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_numbers( text, replacer = \" \", remove_numbers_only = True):\n",
    "    \"\"\"Remove numbers (or numbers + special characters) from a text.\n",
    "    Args\n",
    "        text: string with some text.\n",
    "        replacer: string with the value to substitute the emails.\n",
    "        remove_numbers_only: a boolean to indicate if user wants\n",
    "            to remove only numbers (remove_numbers_only = True) or\n",
    "            \"numbers + special characters\" (remove_numbers_only = False)\n",
    "    Return\n",
    "        text: string with processed text.\"\"\"\n",
    "\n",
    "    # check text param\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # check replacer param\n",
    "    if not isinstance(replacer, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: replacer must be a string\")\n",
    "\n",
    "    # check remove_numbers_only param\n",
    "    if not isinstance(remove_numbers_only, bool):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: remove_numbers_only must be a boolean\")\n",
    "\n",
    "    # import required library\n",
    "    import re\n",
    "\n",
    "    # check if user wants to remove only numbers from words\n",
    "    if remove_numbers_only:\n",
    "        # remove only numbers from words with regex\n",
    "        text = re.sub(\"\\d+\", replacer, text)\n",
    "    # user wants to remove numbers and special characters from the words\n",
    "    else:\n",
    "        # remove numbers and special characters from the words with regex\n",
    "        text = re.sub(\"[^a-zA-Z]+\", replacer, text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def part_of_speech_cleaning( text ):\n",
    "    \"\"\"Use Part-Of-Speech technique to keep only adj, noun, adverb and verbs\n",
    "    on the document once usually they are the words that carry\n",
    "    the most relevant information in a text.\n",
    "    Args\n",
    "        text: a list with senteces of the document.\n",
    "    Return\n",
    "        pos_text: a list with part-of-speech senteces of the document.\"\"\"\n",
    "\n",
    "    # check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        # invalid format\n",
    "        raise Exception(\"Invalid input: text must be a string\")\n",
    "\n",
    "    # import required library\n",
    "    from nltk import pos_tag\n",
    "\n",
    "    # split the text on spaces then\n",
    "    # check apply POS to each word (word, POS).\n",
    "    # Keep the word if the POS of the word is adj [\"JJ\"],\n",
    "    # noun [\"NN\"], adverb [\"RB\"] or verbs [\"VB\"].\n",
    "    # Otherwise, remove the word\n",
    "    pos_text = [ word for word, pos in pos_tag( text.split() )\n",
    "                 if pos.startswith( (\"JJ\", \"NN\", \"RB\", \"VB\") ) ]\n",
    "\n",
    "    # join the words together to compose a text (instead of a list)\n",
    "    pos_text = \" \".join(pos_text)\n",
    "    # remove any additional leading of trailing spaces\n",
    "    pos_text = pos_text.strip()\n",
    "\n",
    "    return pos_text\n",
    "\n",
    "\n",
    "def clean_document( split_document, remove_numbers_only = True ):\n",
    "    \"\"\"Clean the document text. Clean means:\n",
    "    (1) remove the emails on the article\n",
    "    (2) remove the mentions (@someone) on the article\n",
    "    (3) remove the hashtags (#something) on the article\n",
    "    (4) remove the urls on the article\n",
    "    (5) remove html tags (<tag>something</tag>) on the article\n",
    "    (6) lower the case of all words in the article\n",
    "    (7) remove words that are commposed of only digitis\n",
    "    (8) remove puntuation of the sentences\n",
    "    (9) remove stopwords from sentences\n",
    "    (10) lemmatize words in sentences\n",
    "    (11) use part-of-speech technique of the text\n",
    "    (11) remove spaces on the article\n",
    "    Args\n",
    "        split_document: a list with sentences of the document.\n",
    "        remove_numbers_only: a boolean to indicate if user wants\n",
    "            to remove only numbers (remove_numbers_only = True) or\n",
    "            \"numbers + special characters\" (remove_numbers_only = False).\n",
    "            This is the parameter used for calling remove_numbers function.\n",
    "    Return\n",
    "        cleaned_sentences: a list with cleaned senteces of the document.\"\"\"\n",
    "\n",
    "    # remove the emails on the article\n",
    "    removed_emails = [remove_emails( sentence ) for sentence in split_document]\n",
    "\n",
    "    # remove the mentions (@someone) on the article\n",
    "    removed_mentions = [remove_mentions( sentence ) for sentence in removed_emails]\n",
    "\n",
    "    # remove the hashtags (#something) on the article\n",
    "    removed_hashtags = [remove_hashtags( sentence ) for sentence in removed_mentions]\n",
    "\n",
    "    # remove the urls on the article\n",
    "    removed_urls = [remove_urls( sentence ) for sentence in removed_hashtags]\n",
    "\n",
    "    # remove html tags (<tag>something</tag>) on the article\n",
    "    removed_html_tags = [remove_html_tags( sentence ) for sentence in removed_urls]\n",
    "\n",
    "    # lower the case of all words in the article\n",
    "    sentences_lower_cased = [lower_caser(sentence) for sentence in removed_html_tags]\n",
    "\n",
    "    # remove words that are commposed of only digitis\n",
    "    sentences_without_nums = [remove_numbers(sentence, remove_numbers_only = remove_numbers_only) for sentence in sentences_lower_cased]\n",
    "\n",
    "    # remove puntuation of the sentences\n",
    "    sentences_removed_punct = [remove_punctuation(sentence) for sentence in sentences_without_nums]\n",
    "\n",
    "    # remove stopwords from sentences\n",
    "    sentences_removed_stopwords = [remove_stopwords(sentence) for sentence in sentences_removed_punct]\n",
    "\n",
    "    # lemmatize words in sentences\n",
    "    lemmatized_sentences = [lemmatize(sentence) for sentence in sentences_removed_stopwords]\n",
    "\n",
    "    # use part-of-speech on the sentences\n",
    "    pos_sentences = [part_of_speech_cleaning( sentence ) for sentence in lemmatized_sentences]\n",
    "\n",
    "    # remove spaces on the article\n",
    "    cleaned_sentences = [remove_spaces( sentence ) for sentence in pos_sentences]\n",
    "\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5LmBZyxKSt-h"
   },
   "outputs": [],
   "source": [
    "data_imdb.drop_duplicates(inplace=True)\n",
    "data_imdb.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "w6gXDgmqSuGV",
    "outputId": "d532093f-f696-479b-ad48-e934d9d05a72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e9e5ded7-730b-41cb-a030-92c581d1f2f8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>reviewer mentioned watching oz episode hooked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought movie right good job not creative orig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "      <td>catholic taught parochial elementary school nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "      <td>going disagree previous comment side maltin se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "      <td>not expects star trek movie high art fan expec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9e5ded7-730b-41cb-a030-92c581d1f2f8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e9e5ded7-730b-41cb-a030-92c581d1f2f8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e9e5ded7-730b-41cb-a030-92c581d1f2f8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...          1   \n",
       "1      A wonderful little production. <br /><br />The...          1   \n",
       "2      I thought this was a wonderful way to spend ti...          1   \n",
       "3      Basically there's a family where a little boy ...          0   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "...                                                  ...        ...   \n",
       "49995  I thought this movie did a down right good job...          1   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0   \n",
       "49997  I am a Catholic taught in parochial elementary...          0   \n",
       "49998  I'm going to have to disagree with the previou...          0   \n",
       "49999  No one expects the Star Trek movies to be high...          0   \n",
       "\n",
       "                                              clean_text  \n",
       "0      reviewer mentioned watching oz episode hooked ...  \n",
       "1      wonderful little production filming technique ...  \n",
       "2      thought wonderful way spend time hot summer we...  \n",
       "3      basically family little boy jake think zombie ...  \n",
       "4      petter mattei love time money visually stunnin...  \n",
       "...                                                  ...  \n",
       "49995  thought movie right good job not creative orig...  \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...  \n",
       "49997  catholic taught parochial elementary school nu...  \n",
       "49998  going disagree previous comment side maltin se...  \n",
       "49999  not expects star trek movie high art fan expec...  \n",
       "\n",
       "[49582 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imdb['clean_text'] = clean_document(data_imdb['review'])\n",
    "data_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sE-_flCrCkTv"
   },
   "outputs": [],
   "source": [
    "data_imdb.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeTwHFODA9v_"
   },
   "source": [
    "## Preprocessing and modelling data\n",
    "Applying Deep Learning to the preprocessed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bQJxuTx2SuNN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import regularizers, Sequential, layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TUk54pULSaoY"
   },
   "outputs": [],
   "source": [
    "data_imdb.drop_duplicates(inplace=True)\n",
    "data_imdb.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = data_imdb['clean_text']\n",
    "y = data_imdb['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "    \n",
    "\n",
    "X_train_tokenized = tk.texts_to_sequences(X_train)\n",
    "X_test_tokenized = tk.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokenized, dtype='float32', padding='post', maxlen=300)\n",
    "X_test_pad = pad_sequences(X_test_tokenized, dtype='float32', padding='post', maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEN7lSsPSavS",
    "outputId": "49863b38-b9b2-4091-f7b2-3196234187e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 40)          3089680   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20)                4880      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,094,581\n",
      "Trainable params: 3,094,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg_l2 = regularizers.L2(0.3)\n",
    "\n",
    "embedding_size = 40\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(\n",
    "    input_dim= len(tk.word_index)+1,\n",
    "    output_dim=embedding_size,\n",
    "    mask_zero=True\n",
    "))\n",
    "\n",
    "model.add(layers.LSTM(20, kernel_regularizer=reg_l2))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mrhsbiRVmjG",
    "outputId": "effc8d39-40ed-482c-e1e5-c6d41444dabe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "814/814 [==============================] - 182s 217ms/step - loss: 1.5144 - accuracy: 0.7945 - val_loss: 0.4011 - val_accuracy: 0.8638\n",
      "Epoch 2/20\n",
      "814/814 [==============================] - 170s 208ms/step - loss: 0.3010 - accuracy: 0.8970 - val_loss: 0.2913 - val_accuracy: 0.8932\n",
      "Epoch 3/20\n",
      "814/814 [==============================] - 170s 208ms/step - loss: 0.2398 - accuracy: 0.9196 - val_loss: 0.2922 - val_accuracy: 0.8959\n",
      "Epoch 4/20\n",
      "814/814 [==============================] - 170s 209ms/step - loss: 0.2147 - accuracy: 0.9278 - val_loss: 0.3097 - val_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "814/814 [==============================] - 171s 210ms/step - loss: 0.1923 - accuracy: 0.9362 - val_loss: 0.4031 - val_accuracy: 0.8548\n",
      "Epoch 6/20\n",
      "814/814 [==============================] - 171s 209ms/step - loss: 0.1805 - accuracy: 0.9409 - val_loss: 0.3179 - val_accuracy: 0.8738\n",
      "Epoch 7/20\n",
      "814/814 [==============================] - 170s 209ms/step - loss: 0.1696 - accuracy: 0.9445 - val_loss: 0.3390 - val_accuracy: 0.8785\n",
      "Epoch 8/20\n",
      "814/814 [==============================] - 168s 206ms/step - loss: 0.1600 - accuracy: 0.9473 - val_loss: 0.2906 - val_accuracy: 0.8932\n",
      "Epoch 9/20\n",
      "814/814 [==============================] - 168s 206ms/step - loss: 0.1559 - accuracy: 0.9475 - val_loss: 0.3045 - val_accuracy: 0.8921\n",
      "Epoch 10/20\n",
      "814/814 [==============================] - 169s 207ms/step - loss: 0.1485 - accuracy: 0.9510 - val_loss: 0.3340 - val_accuracy: 0.8883\n",
      "Epoch 11/20\n",
      "814/814 [==============================] - 168s 207ms/step - loss: 0.1426 - accuracy: 0.9522 - val_loss: 0.3049 - val_accuracy: 0.8909\n",
      "Epoch 12/20\n",
      "814/814 [==============================] - 170s 208ms/step - loss: 0.1372 - accuracy: 0.9540 - val_loss: 0.2887 - val_accuracy: 0.8874\n",
      "Epoch 13/20\n",
      "814/814 [==============================] - 171s 210ms/step - loss: 0.1337 - accuracy: 0.9556 - val_loss: 0.2954 - val_accuracy: 0.8815\n",
      "Epoch 14/20\n",
      "814/814 [==============================] - 172s 211ms/step - loss: 0.1302 - accuracy: 0.9559 - val_loss: 0.3355 - val_accuracy: 0.8872\n",
      "Epoch 15/20\n",
      "814/814 [==============================] - 170s 209ms/step - loss: 0.1280 - accuracy: 0.9578 - val_loss: 0.3144 - val_accuracy: 0.8894\n",
      "Epoch 16/20\n",
      "814/814 [==============================] - 170s 209ms/step - loss: 0.1229 - accuracy: 0.9590 - val_loss: 0.3258 - val_accuracy: 0.8841\n",
      "Epoch 17/20\n",
      "814/814 [==============================] - 168s 206ms/step - loss: 0.1222 - accuracy: 0.9599 - val_loss: 0.3406 - val_accuracy: 0.8875\n",
      "Epoch 18/20\n",
      "814/814 [==============================] - 167s 206ms/step - loss: 0.1182 - accuracy: 0.9604 - val_loss: 0.3841 - val_accuracy: 0.8830\n",
      "Epoch 19/20\n",
      "814/814 [==============================] - 167s 205ms/step - loss: 0.1173 - accuracy: 0.9620 - val_loss: 0.3641 - val_accuracy: 0.8868\n",
      "Epoch 20/20\n",
      "814/814 [==============================] - 167s 206ms/step - loss: 0.1149 - accuracy: 0.9623 - val_loss: 0.3347 - val_accuracy: 0.8874\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model_ = model.fit(X_train_pad, y_train, validation_split=0.25, epochs=20, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyy0AuaVVtHa",
    "outputId": "ad83a572-c50a-4670-d79e-584c421eb675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 8s 67ms/step - loss: 0.3408 - accuracy: 0.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34080061316490173, 0.8868571519851685]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate\n",
    "\n",
    "results = model.evaluate(X_test_pad, y_test, batch_size=128)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "just-imdb-data-deep",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
